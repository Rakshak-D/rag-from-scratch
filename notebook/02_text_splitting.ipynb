{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# This notebook only covers PDF/Directory loading and chunking. No embedding, or vector storage is done here.",
   "id": "20f9043d22866e3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PDF Ingestion",
   "id": "9e66f7d74045970"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.165887300Z",
     "start_time": "2026-01-14T12:37:12.423330900Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader #Used to load PDF .\n",
    "from pathlib import Path # Used to find the path directory or file .\n",
    "from langchain_core.documents import Document # Used specifying type to return ."
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why PDF Loading Needs Care\n",
    "\n",
    "PDFs are not plain text files. They often contain:\n",
    "- Empty pages\n",
    "- Headers/footers\n",
    "- Irregular formatting\n",
    "- Very large text blocks\n",
    "\n",
    "Before chunking or embedding, we must:\n",
    "- Filter empty pages\n",
    "- Track file size\n",
    "- Preserve source metadata\n",
    "- Estimate token usage to avoid model limits\n"
   ],
   "id": "8143362dbc702eee"
  },
  {
   "cell_type": "code",
   "id": "cd995280ff389b4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.201782700Z",
     "start_time": "2026-01-14T12:37:21.176433300Z"
    }
   },
   "source": [
    "# The following function is used to load all the PDF from a directory .\n",
    "def loading_pdf(dir_path)->list[Document]: # Return Type .\n",
    "    all_pdf_size_mb=0.0  # Initializing size to 0 .\n",
    "    all_pdf_documents=[] # Used to store all the PDF documents .\n",
    "    total_tokens=0\n",
    "    #Trying to get the PDF's path from given directory .\n",
    "    pdf_dir=Path(dir_path) #Getting the path of the directory .\n",
    "    if not pdf_dir.is_dir(): #Checking if the directory exists .\n",
    "        raise NotADirectoryError(f\"{pdf_dir} is not a valid directory .\")\n",
    "    else:\n",
    "        print(f\"The directory path is : {pdf_dir} \") # Printing the Directory Path .\n",
    "\n",
    "        pdfs=list(pdf_dir.rglob(\"*.pdf\")) # Making a list to store all the PDF paths . Can use glob(\"**/*.pdf\") .\n",
    "        print(f\"Number of pdf's in the directory : {len(pdfs)} \") # Printing Number of PDF's in the directory.\n",
    "\n",
    "        #Loading all the PDF's using list of paths .\n",
    "\n",
    "        print(\"=\"*20,\"PDF LOAD SUMMARY\",\"=\"*20)\n",
    "        print(\"-\"*45)\n",
    "        for serial,pdf_path in enumerate(pdfs):\n",
    "            print(f\"{serial+1})----->Loading {pdf_path.name} .\") # Serial number of the PDF .\n",
    "            size_bytes=pdf_path.stat().st_size # Checking the size of PDF .\n",
    "            size_mb=(size_bytes/(1024**2)) # Converting into Mb .\n",
    "            print(f\"File size : {size_mb:.3f} Mb .\") # Printing File size of the PDF .\n",
    "            try:\n",
    "                pdf_loader=PyPDFLoader(pdf_path) # Trying to load the PDF into document .\n",
    "                pdf=pdf_loader.load()\n",
    "                pdf_tokens=0\n",
    "                filtered_pages=[] # Used to get filtered pages and remove empty pages .\n",
    "                for page in pdf: # Adding extra metadata .\n",
    "                    if not page.page_content.strip(): # Skipping empty pages .\n",
    "                        continue\n",
    "                    else:\n",
    "                        page.metadata.update({\n",
    "                            'source': str(pdf_path),\n",
    "                            'file_name':pdf_path.name,\n",
    "                            'file_type':\"pdf\"\n",
    "                        })\n",
    "                        page_tokens=len(page.page_content)//4 # Counts tokens per page .\n",
    "                        pdf_tokens+=page_tokens # Adding current page tokens to previous tokens .\n",
    "                        page.metadata[\"estimated_tokens\"] = page_tokens # Storing the tokens of each page in metadata .\n",
    "                        filtered_pages.append(page)\n",
    "                total_tokens+=pdf_tokens # Adding current PDF tokens to previous PDF .\n",
    "                print(f\"Number of pages loaded : {len(filtered_pages)} .\") # Printing number of pages or documents  loaded in this PDF .\n",
    "                print(f\"Estimated Tokens of the pdf : {pdf_tokens} tokens .\") # Estimated token in PDF .\n",
    "                print(\"Loaded file successfully . \") # Confirming the PDF loaded .\n",
    "                print(\"-\"*45)\n",
    "\n",
    "                all_pdf_documents.extend(filtered_pages) # Using extend to add the documents one by one instead of complete PDF .\n",
    "                all_pdf_size_mb+=size_mb # Add previous file sizes .\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing the file {pdf_path.name} . Error {e}\") # Exception Handling .\n",
    "\n",
    "        print(\"-\"*60)\n",
    "        print(f\"Final number of documents/pages loaded : {len(all_pdf_documents)}\") # Printing final number of documents collected through all PDF's .\n",
    "        print(f\"Total sizes of all pdf's: {all_pdf_size_mb:.3f} Mb .\") # Total size of all the PDF's collectively .\n",
    "        print(f\"Estimated Tokens of all the pdf's : {total_tokens} tokens .\") # Estimated total number of tokens through all documents .\n",
    "        print(\"-\"*60)\n",
    "\n",
    "        return all_pdf_documents # returning all the collected documents ."
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "dac10826667afa01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.113896900Z",
     "start_time": "2026-01-14T12:37:21.203787300Z"
    }
   },
   "source": "documents=loading_pdf(\"../data\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory path is : ..\\data \n",
      "Number of pdf's in the directory : 2 \n",
      "==================== PDF LOAD SUMMARY ====================\n",
      "---------------------------------------------\n",
      "1)----->Loading He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf .\n",
      "File size : 0.781 Mb .\n",
      "Number of pages loaded : 12 .\n",
      "Estimated Tokens of the pdf : 14837 tokens .\n",
      "Loaded file successfully . \n",
      "---------------------------------------------\n",
      "2)----->Loading Lewis et al. - 2021 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf .\n",
      "File size : 0.844 Mb .\n",
      "Number of pages loaded : 19 .\n",
      "Estimated Tokens of the pdf : 17256 tokens .\n",
      "Loaded file successfully . \n",
      "---------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Final number of documents/pages loaded : 31\n",
      "Total sizes of all pdf's: 1.626 Mb .\n",
      "Estimated Tokens of all the pdf's : 32093 tokens .\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Token Estimation (Important Concept)\n",
    "\n",
    "LLMs do not process text as characters or words ‚Äî they process **tokens**.\n",
    "\n",
    "A commonly used heuristic:\n",
    "> **1 token ‚âà 4 characters (English text)**\n",
    "\n",
    "We use:\n",
    "```python\n",
    "len(text) // 4\n"
   ],
   "id": "90306b77755c6c9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.194518300Z",
     "start_time": "2026-01-14T12:37:22.186345900Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents[0]) # Only loading first document due to large number of documents .",
   "id": "e8eea52c7dcdea97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Deep Residual Learning for Image Recognition\n",
      "Kaiming He Xiangyu Zhang Shaoqing Ren Jian Sun\n",
      "Microsoft Research\n",
      "{kahe, v-xiangz, v-shren, jiansun}@microsoft.com\n",
      "Abstract\n",
      "Deeper neural networks are more difÔ¨Åcult to train. We\n",
      "present a residual learning framework to ease the training\n",
      "of networks that are substantially deeper than those used\n",
      "previously. We explicitly reformulate the layers as learn-\n",
      "ing residual functions with reference to the layer inputs, in-\n",
      "stead of learning unreferenced functions. We provide com-\n",
      "prehensive empirical evidence showing that these residual\n",
      "networks are easier to optimize, and can gain accuracy from\n",
      "considerably increased depth. On the ImageNet dataset we\n",
      "evaluate residual nets with a depth of up to 152 layers‚Äî8√ó\n",
      "deeper than VGG nets [41] but still having lower complex-\n",
      "ity. An ensemble of these residual nets achieves 3.57% error\n",
      "on the ImageNettest set. This result won the 1st place on the\n",
      "ILSVRC 2015 classiÔ¨Åcation task. We also present analysis\n",
      "on CIFAR-10 with 100 and 1000 layers.\n",
      "The depth of representations is of central importance\n",
      "for many visual recognition tasks. Solely due to our ex-\n",
      "tremely deep representations, we obtain a 28% relative im-\n",
      "provement on the COCO object detection dataset. Deep\n",
      "residual nets are foundations of our submissions to ILSVRC\n",
      "& COCO 2015 competitions 1, where we also won the 1st\n",
      "places on the tasks of ImageNet detection, ImageNet local-\n",
      "ization, COCO detection, and COCO segmentation.\n",
      "1. Introduction\n",
      "Deep convolutional neural networks [22, 21] have led\n",
      "to a series of breakthroughs for image classiÔ¨Åcation [21,\n",
      "50, 40]. Deep networks naturally integrate low/mid/high-\n",
      "level features [50] and classiÔ¨Åers in an end-to-end multi-\n",
      "layer fashion, and the ‚Äúlevels‚Äù of features can be enriched\n",
      "by the number of stacked layers (depth). Recent evidence\n",
      "[41, 44] reveals that network depth is of crucial importance,\n",
      "and the leading results [41, 44, 13, 16] on the challenging\n",
      "ImageNet dataset [36] all exploit ‚Äúvery deep‚Äù [41] models,\n",
      "with a depth of sixteen [41] to thirty [16]. Many other non-\n",
      "trivial visual recognition tasks [8, 12, 7, 32, 27] have also\n",
      "1http://image-net.org/challenges/LSVRC/2015/ and\n",
      "http://mscoco.org/dataset/#detections-challenge2015.\n",
      "0 1 2 3 4 5 60 \n",
      "10\n",
      "20\n",
      "iter. (1e4)\n",
      "training error (%)\n",
      " \n",
      " \n",
      "0 1 2 3 4 5 60\n",
      "10\n",
      "20\n",
      "iter. (1e4)\n",
      "test error (%)\n",
      " \n",
      " \n",
      "56-layer\n",
      "20-layer\n",
      "56-layer\n",
      "20-layer\n",
      "Figure 1. Training error (left) and test error (right) on CIFAR-10\n",
      "with 20-layer and 56-layer ‚Äúplain‚Äù networks. The deeper network\n",
      "has higher training error, and thus test error. Similar phenomena\n",
      "on ImageNet is presented in Fig. 4.\n",
      "greatly beneÔ¨Åted from very deep models.\n",
      "Driven by the signiÔ¨Åcance of depth, a question arises:Is\n",
      "learning better networks as easy as stacking more layers?\n",
      "An obstacle to answering this question was the notorious\n",
      "problem of vanishing/exploding gradients [1, 9], which\n",
      "hamper convergence from the beginning. This problem,\n",
      "however, has been largely addressed by normalized initial-\n",
      "ization [23, 9, 37, 13] and intermediate normalization layers\n",
      "[16], which enable networks with tens of layers to start con-\n",
      "verging for stochastic gradient descent (SGD) with back-\n",
      "propagation [22].\n",
      "When deeper networks are able to start converging, a\n",
      "degradation problem has been exposed: with the network\n",
      "depth increasing, accuracy gets saturated (which might be\n",
      "unsurprising) and then degrades rapidly. Unexpectedly,\n",
      "such degradation is not caused by overÔ¨Åtting , and adding\n",
      "more layers to a suitably deep model leads to higher train-\n",
      "ing error, as reported in [11, 42] and thoroughly veriÔ¨Åed by\n",
      "our experiments. Fig. 1 shows a typical example.\n",
      "The degradation (of training accuracy) indicates that not\n",
      "all systems are similarly easy to optimize. Let us consider a\n",
      "shallower architecture and its deeper counterpart that adds\n",
      "more layers onto it. There exists a solution by construction\n",
      "to the deeper model: the added layers are identity mapping,\n",
      "and the other layers are copied from the learned shallower\n",
      "model. The existence of this constructed solution indicates\n",
      "that a deeper model should produce no higher training error\n",
      "than its shallower counterpart. But experiments show that\n",
      "our current solvers on hand are unable to Ô¨Ånd solutions that\n",
      "1\n",
      "arXiv:1512.03385v1  [cs.CV]  10 Dec 2015' metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-12-11T01:13:45+00:00', 'author': '', 'keywords': '', 'moddate': '2015-12-11T01:13:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'file_name': 'He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf', 'file_type': 'pdf', 'estimated_tokens': 1071}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.202039100Z",
     "start_time": "2026-01-14T12:37:22.195524400Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents[0].page_content) # Page content of first document . First page the PDF .",
   "id": "e57c7fae0c7c7745",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Residual Learning for Image Recognition\n",
      "Kaiming He Xiangyu Zhang Shaoqing Ren Jian Sun\n",
      "Microsoft Research\n",
      "{kahe, v-xiangz, v-shren, jiansun}@microsoft.com\n",
      "Abstract\n",
      "Deeper neural networks are more difÔ¨Åcult to train. We\n",
      "present a residual learning framework to ease the training\n",
      "of networks that are substantially deeper than those used\n",
      "previously. We explicitly reformulate the layers as learn-\n",
      "ing residual functions with reference to the layer inputs, in-\n",
      "stead of learning unreferenced functions. We provide com-\n",
      "prehensive empirical evidence showing that these residual\n",
      "networks are easier to optimize, and can gain accuracy from\n",
      "considerably increased depth. On the ImageNet dataset we\n",
      "evaluate residual nets with a depth of up to 152 layers‚Äî8√ó\n",
      "deeper than VGG nets [41] but still having lower complex-\n",
      "ity. An ensemble of these residual nets achieves 3.57% error\n",
      "on the ImageNettest set. This result won the 1st place on the\n",
      "ILSVRC 2015 classiÔ¨Åcation task. We also present analysis\n",
      "on CIFAR-10 with 100 and 1000 layers.\n",
      "The depth of representations is of central importance\n",
      "for many visual recognition tasks. Solely due to our ex-\n",
      "tremely deep representations, we obtain a 28% relative im-\n",
      "provement on the COCO object detection dataset. Deep\n",
      "residual nets are foundations of our submissions to ILSVRC\n",
      "& COCO 2015 competitions 1, where we also won the 1st\n",
      "places on the tasks of ImageNet detection, ImageNet local-\n",
      "ization, COCO detection, and COCO segmentation.\n",
      "1. Introduction\n",
      "Deep convolutional neural networks [22, 21] have led\n",
      "to a series of breakthroughs for image classiÔ¨Åcation [21,\n",
      "50, 40]. Deep networks naturally integrate low/mid/high-\n",
      "level features [50] and classiÔ¨Åers in an end-to-end multi-\n",
      "layer fashion, and the ‚Äúlevels‚Äù of features can be enriched\n",
      "by the number of stacked layers (depth). Recent evidence\n",
      "[41, 44] reveals that network depth is of crucial importance,\n",
      "and the leading results [41, 44, 13, 16] on the challenging\n",
      "ImageNet dataset [36] all exploit ‚Äúvery deep‚Äù [41] models,\n",
      "with a depth of sixteen [41] to thirty [16]. Many other non-\n",
      "trivial visual recognition tasks [8, 12, 7, 32, 27] have also\n",
      "1http://image-net.org/challenges/LSVRC/2015/ and\n",
      "http://mscoco.org/dataset/#detections-challenge2015.\n",
      "0 1 2 3 4 5 60 \n",
      "10\n",
      "20\n",
      "iter. (1e4)\n",
      "training error (%)\n",
      " \n",
      " \n",
      "0 1 2 3 4 5 60\n",
      "10\n",
      "20\n",
      "iter. (1e4)\n",
      "test error (%)\n",
      " \n",
      " \n",
      "56-layer\n",
      "20-layer\n",
      "56-layer\n",
      "20-layer\n",
      "Figure 1. Training error (left) and test error (right) on CIFAR-10\n",
      "with 20-layer and 56-layer ‚Äúplain‚Äù networks. The deeper network\n",
      "has higher training error, and thus test error. Similar phenomena\n",
      "on ImageNet is presented in Fig. 4.\n",
      "greatly beneÔ¨Åted from very deep models.\n",
      "Driven by the signiÔ¨Åcance of depth, a question arises:Is\n",
      "learning better networks as easy as stacking more layers?\n",
      "An obstacle to answering this question was the notorious\n",
      "problem of vanishing/exploding gradients [1, 9], which\n",
      "hamper convergence from the beginning. This problem,\n",
      "however, has been largely addressed by normalized initial-\n",
      "ization [23, 9, 37, 13] and intermediate normalization layers\n",
      "[16], which enable networks with tens of layers to start con-\n",
      "verging for stochastic gradient descent (SGD) with back-\n",
      "propagation [22].\n",
      "When deeper networks are able to start converging, a\n",
      "degradation problem has been exposed: with the network\n",
      "depth increasing, accuracy gets saturated (which might be\n",
      "unsurprising) and then degrades rapidly. Unexpectedly,\n",
      "such degradation is not caused by overÔ¨Åtting , and adding\n",
      "more layers to a suitably deep model leads to higher train-\n",
      "ing error, as reported in [11, 42] and thoroughly veriÔ¨Åed by\n",
      "our experiments. Fig. 1 shows a typical example.\n",
      "The degradation (of training accuracy) indicates that not\n",
      "all systems are similarly easy to optimize. Let us consider a\n",
      "shallower architecture and its deeper counterpart that adds\n",
      "more layers onto it. There exists a solution by construction\n",
      "to the deeper model: the added layers are identity mapping,\n",
      "and the other layers are copied from the learned shallower\n",
      "model. The existence of this constructed solution indicates\n",
      "that a deeper model should produce no higher training error\n",
      "than its shallower counterpart. But experiments show that\n",
      "our current solvers on hand are unable to Ô¨Ånd solutions that\n",
      "1\n",
      "arXiv:1512.03385v1  [cs.CV]  10 Dec 2015\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.209872300Z",
     "start_time": "2026-01-14T12:37:22.203039500Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents[0].metadata) # Metadata of first document . First page the PDF .",
   "id": "49e795593783d66f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-12-11T01:13:45+00:00', 'author': '', 'keywords': '', 'moddate': '2015-12-11T01:13:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'file_name': 'He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf', 'file_type': 'pdf', 'estimated_tokens': 1071}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chunking",
   "id": "9a250fd1c3ac9b9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why Text Chunking Is Required\n",
    "\n",
    "Embedding models and LLMs have **context length limits**.\n",
    "\n",
    "Large documents must be split into smaller chunks to:\n",
    "- Fit model constraints\n",
    "- Improve semantic retrieval\n",
    "- Avoid truncation or failures\n",
    "- Preserve local context\n",
    "\n",
    "Chunking is a **mandatory step** in any RAG pipeline."
   ],
   "id": "1eec2714db812a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.216950100Z",
     "start_time": "2026-01-14T12:37:22.209872300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Used to split large data into comparatively smaller chunks of data .\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter # Function used to split the data ."
   ],
   "id": "f618b6e0d00732bf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## RecursiveCharacterTextSplitter Explained\n",
    "\n",
    "This splitter attempts to preserve semantic structure by splitting text **recursively** using:\n",
    "\n",
    "1. Paragraph breaks (`\\n\\n`)\n",
    "2. Line breaks (`\\n`)\n",
    "3. Spaces\n",
    "4. Character-level splits (last resort)\n",
    "\n",
    "This approach avoids cutting sentences or ideas whenever possible.\n"
   ],
   "id": "be8cac78dce5b181"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.227358800Z",
     "start_time": "2026-01-14T12:37:22.217951500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The following function takes list of Document as input and chunks data into smaller Documents .\n",
    "def document_splitters(documents:list[Document],chunk_size=1000,chunk_overlap=200)->list[Document]:\n",
    "    # Chunk_size -> number of character in a chunk .\n",
    "    # Chunk_overlap -> number of previous chunk characters in the beginning of this chunk for relevance .\n",
    "    # add_start_index -> Due to overlap we need to specify from where the present chunk starts from .\n",
    "    # separators -> Delimiter used for separating characters .\n",
    "    # Length_function -> Method used to split chunks . Eg -> characters , tokens ...\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap,add_start_index=True,separators=[\"\\n\\n\",\"\\n\",\" \",\"\"],length_function=len)\n",
    "\n",
    "    # Checking if the documents is valid with respect to type .\n",
    "    if not documents:\n",
    "        raise ValueError(\"Invalid documents .\")\n",
    "    if not all(isinstance(d,Document) for d in documents):\n",
    "        raise TypeError(\"All the item in documents must be of Document type .\")\n",
    "\n",
    "    split_docs=text_splitter.split_documents(documents) # Splitting the documents based on given parameters .\n",
    "    if not split_docs: # Checking if the documents have been split .\n",
    "        print(\"No chunks created .\")\n",
    "        return [] # Returning empty list indicating no chunks were created .\n",
    "    print(f\"{len(documents)} documents is split into {len(split_docs)} chunks .\") # Printing number of chunks created with respect to original documents .\n",
    "\n",
    "    tokens=0 #Initializing tokens to 0 .\n",
    "\n",
    "    for doc in split_docs: # Inserting tokens as for future use .\n",
    "        chunk_tokens=len(doc.page_content)//4\n",
    "        tokens+=chunk_tokens\n",
    "        doc.metadata.update(\n",
    "            {\n",
    "                'estimated_tokens':chunk_tokens\n",
    "            }\n",
    "        )\n",
    "    # Printing essential details after chunking the data .\n",
    "    print(\"=\"*30,\"Chunking SUMMARY\",\"=\"*30)\n",
    "    print(\"-\"*80)\n",
    "    max_tokens=max(t.metadata['estimated_tokens'] for t in split_docs)  # Maximum tokens in a single chunk .\n",
    "    min_tokens=min(t.metadata['estimated_tokens'] for t in split_docs)  # Minimum tokens in a single chunk .\n",
    "    avg_tokens=tokens//len(split_docs)                                 # Average tokens from all the chunks .\n",
    "    print(f\"---> Maximum tokens in a chunk : {max_tokens} tokens\")\n",
    "    print(f\"---> Minimum tokens in a chunk : {min_tokens} tokens\")\n",
    "    print(f\"---> Average tokens from each chunk : {avg_tokens} tokens .\")\n",
    "    print(f\"---> Estimated tokens from all the documents after chunking : {tokens} tokens .\") # Estimated tokens after chunking . Higher than original documents due to chunk overlapping .\n",
    "    print(\"-\"*80)\n",
    "    return split_docs # Returning documents after chunking ."
   ],
   "id": "107a380df7d39af1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.238107700Z",
     "start_time": "2026-01-14T12:37:22.228358900Z"
    }
   },
   "cell_type": "code",
   "source": "chunks=document_splitters(documents)",
   "id": "48b8a9ecbbb95538",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 documents is split into 170 chunks .\n",
      "============================== Chunking SUMMARY ==============================\n",
      "--------------------------------------------------------------------------------\n",
      "---> Maximum tokens in a chunk : 249 tokens\n",
      "---> Minimum tokens in a chunk : 50 tokens\n",
      "---> Average tokens from each chunk : 223 tokens .\n",
      "---> Estimated tokens from all the documents after chunking : 37984 tokens .\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.245679700Z",
     "start_time": "2026-01-14T12:37:22.239108800Z"
    }
   },
   "cell_type": "code",
   "source": "print(chunks[1])",
   "id": "cf809e275390bbca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='ity. An ensemble of these residual nets achieves 3.57% error\n",
      "on the ImageNettest set. This result won the 1st place on the\n",
      "ILSVRC 2015 classiÔ¨Åcation task. We also present analysis\n",
      "on CIFAR-10 with 100 and 1000 layers.\n",
      "The depth of representations is of central importance\n",
      "for many visual recognition tasks. Solely due to our ex-\n",
      "tremely deep representations, we obtain a 28% relative im-\n",
      "provement on the COCO object detection dataset. Deep\n",
      "residual nets are foundations of our submissions to ILSVRC\n",
      "& COCO 2015 competitions 1, where we also won the 1st\n",
      "places on the tasks of ImageNet detection, ImageNet local-\n",
      "ization, COCO detection, and COCO segmentation.\n",
      "1. Introduction\n",
      "Deep convolutional neural networks [22, 21] have led\n",
      "to a series of breakthroughs for image classiÔ¨Åcation [21,\n",
      "50, 40]. Deep networks naturally integrate low/mid/high-\n",
      "level features [50] and classiÔ¨Åers in an end-to-end multi-\n",
      "layer fashion, and the ‚Äúlevels‚Äù of features can be enriched' metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-12-11T01:13:45+00:00', 'author': '', 'keywords': '', 'moddate': '2015-12-11T01:13:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'file_name': 'He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf', 'file_type': 'pdf', 'estimated_tokens': 240, 'start_index': 812}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.251967100Z",
     "start_time": "2026-01-14T12:37:22.245679700Z"
    }
   },
   "cell_type": "code",
   "source": "print(chunks[1].page_content)",
   "id": "a703b4966e5012bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ity. An ensemble of these residual nets achieves 3.57% error\n",
      "on the ImageNettest set. This result won the 1st place on the\n",
      "ILSVRC 2015 classiÔ¨Åcation task. We also present analysis\n",
      "on CIFAR-10 with 100 and 1000 layers.\n",
      "The depth of representations is of central importance\n",
      "for many visual recognition tasks. Solely due to our ex-\n",
      "tremely deep representations, we obtain a 28% relative im-\n",
      "provement on the COCO object detection dataset. Deep\n",
      "residual nets are foundations of our submissions to ILSVRC\n",
      "& COCO 2015 competitions 1, where we also won the 1st\n",
      "places on the tasks of ImageNet detection, ImageNet local-\n",
      "ization, COCO detection, and COCO segmentation.\n",
      "1. Introduction\n",
      "Deep convolutional neural networks [22, 21] have led\n",
      "to a series of breakthroughs for image classiÔ¨Åcation [21,\n",
      "50, 40]. Deep networks naturally integrate low/mid/high-\n",
      "level features [50] and classiÔ¨Åers in an end-to-end multi-\n",
      "layer fashion, and the ‚Äúlevels‚Äù of features can be enriched\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üßæ Metadata Propagation\n",
    "\n",
    "Each chunk preserves and extends metadata such as:\n",
    "\n",
    "- `source` ‚Äì original file path\n",
    "- `file_name` ‚Äì PDF name\n",
    "- `file_type` ‚Äì \"pdf\"\n",
    "- `estimated_tokens` ‚Äì token estimate for the chunk\n",
    "- `start_index` ‚Äì position in source text\n",
    "\n",
    "This metadata is critical for:\n",
    "- Retrieval filtering\n",
    "- Source attribution\n",
    "- Cost estimation"
   ],
   "id": "e44e0ebc4f49f27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:22.260052400Z",
     "start_time": "2026-01-14T12:37:22.252969400Z"
    }
   },
   "cell_type": "code",
   "source": "print(chunks[1].metadata)",
   "id": "785fa0ddfddc5605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-12-11T01:13:45+00:00', 'author': '', 'keywords': '', 'moddate': '2015-12-11T01:13:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'file_name': 'He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf', 'file_type': 'pdf', 'estimated_tokens': 240, 'start_index': 812}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Important Note: Documents Are NOT Embeddings\n",
    "\n",
    "The standard RAG pipeline is:\n",
    "\n",
    "1. Documents are loaded and cleaned.\n",
    "2. Documents are split into smaller chunks.\n",
    "3. Chunks are converted into embeddings.\n",
    "4. Embeddings are stored in a vector database.\n",
    "\n",
    "This notebook stops at Step 2."
   ],
   "id": "a1d3ad0210aaf56c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What comes next\n",
    "- Embedding generation\n",
    "- Vector store ingestion\n",
    "- Retrieval (RAG)"
   ],
   "id": "9b906bf838cb0a77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Next step: Embedding the chunked data before storing into a vector store .\n",
   "id": "86800bbffb2d3bea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# This notebook only covers embedding. No Vector storage is done here.",
   "id": "364e77afd0d22919"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embeddings",
   "id": "2a4f44a6929bef47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What Are Embeddings?\n",
    "\n",
    "Embeddings are numerical representations of text that capture semantic meaning.\n",
    "They transform words, sentences, or documents into high-dimensional vectors where semantically similar content is mapped to nearby points in vector space.\n",
    "\n",
    "In Retrieval-Augmented Generation (RAG) systems, embeddings enable:\n",
    "- Semantic search beyond keyword matching\n",
    "- Retrieval of contextually relevant documents\n",
    "- Efficient vector similarity search\n"
   ],
   "id": "32e71ee42d80dfb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why Sentence Transformers?\n",
    "- Pre-trained models optimized for semantic similarity.\n",
    "- Generate dense vector representations.\n",
    "- Enable semantic search beyond keyword matching."
   ],
   "id": "e20022b8663d8c3b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:17.271809700Z",
     "start_time": "2026-01-14T12:37:09.014798400Z"
    }
   },
   "source": [
    "# Used to import pretrained models .\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.334179200Z",
     "start_time": "2026-01-14T12:37:17.278808800Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_model=SentenceTransformer(\"all-MiniLM-L6-v2\") # Using all-MiniLM-L6-v2 as a pretrained model for embedding .",
   "id": "291eab42683909a5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Configuration\n",
    "- The all-MiniLM-L6-v2 model used in the notebook features:\n",
    "\n",
    "- Architecture: A BertModel structure.\n",
    "\n",
    "- Max Sequence Length: Capable of processing up to 256 tokens per input.\n",
    "\n",
    "- Precision: Uses torch.float32 for its numerical calculations."
   ],
   "id": "7fb47448bbc1b9e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.460838100Z",
     "start_time": "2026-01-14T12:37:21.434488400Z"
    }
   },
   "cell_type": "code",
   "source": "print(embedding_model) # About the model .",
   "id": "3f2d3422a35f261e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.493016700Z",
     "start_time": "2026-01-14T12:37:21.461847600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(embedding_model.device) # Model works on cpu\n",
    "print(embedding_model.cpu()) # Model parameters or features .\n",
    "print(embedding_model.transformers_model) # It uses Bert architecture ."
   ],
   "id": "5e599f8918d8156f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 384)\n",
      "    (token_type_embeddings): Embedding(2, 384)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.516554400Z",
     "start_time": "2026-01-14T12:37:21.494016500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(embedding_model.backend) # The framework or attributes used to make the model .\n",
    "print(embedding_model.dtype) # Type of the model ."
   ],
   "id": "cae69e00b06e6c0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch\n",
      "torch.float32\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.541130700Z",
     "start_time": "2026-01-14T12:37:21.517557Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_model.get_sentence_embedding_dimension() # Embedding dimensions of model .",
   "id": "5a0f541a52c5ad16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.551859Z",
     "start_time": "2026-01-14T12:37:21.543135100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Other libraries used for data manipulation purposes .\n",
    "import numpy as np\n",
    "from typing import Union,List"
   ],
   "id": "62182bf592fa6334",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Key Functionalities:\n",
    "- Model Initialization: Handles the loading of the SentenceTransformer model and confirms its dimensions.\n",
    "\n",
    "- Input Validation: Ensures that only non-empty strings or lists of strings are processed.\n",
    "\n",
    "- Batch Processing: Encodes multiple texts efficiently using a default batch_size of 32.\n",
    "\n",
    "- Normalization: Automatically normalizes the output vectors, which is critical for performing similarity searches late."
   ],
   "id": "9efecd29d7943fe2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:21.571888900Z",
     "start_time": "2026-01-14T12:37:21.552859700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The following class helps to load and generate the embeddings of the texts .\n",
    "class EmbeddingManager:\n",
    "    def __init__(self,embedding_model_name:str=\"all-MiniLM-L6-v2\")->None: #default model is all-MiniLM-L6-v2 .\n",
    "        self.embedding_model_name=embedding_model_name\n",
    "        self.embedding_model=None\n",
    "        self._load_model() # Self function to load model .\n",
    "    def _load_model(self): # This functions try to load models .\n",
    "        try:\n",
    "            print(f\"Loading Embedding Model : {self.embedding_model_name} .\")\n",
    "            self.embedding_model=SentenceTransformer(self.embedding_model_name) # Loading model .\n",
    "            print(f\"Embedding dimensions of the model is : {self.embedding_model.get_sentence_embedding_dimension()} dimensions .\") # Prints the dimension of model .\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading {self.embedding_model_name} model\") from e # Exception handling .\n",
    "\n",
    "    # The following functions embeds the given strings .\n",
    "    def generate_embeddings(self,texts:Union[str,List[str]],batch_size=32)->np.ndarray:\n",
    "        if self.embedding_model is None:\n",
    "            raise ValueError(\"Model not found .\") # Raises error if model is not loaded .\n",
    "        if isinstance(texts,str): # Checks if the input is string .\n",
    "            if not texts.strip():\n",
    "                raise ValueError(\"Text cannot be empty .\") # Raises error if the given input is not string .\n",
    "        elif isinstance(texts,list):\n",
    "            if len(texts)==0:\n",
    "                raise ValueError(\"Texts list is empty .\") # Raises error if the given input is not list of strings .\n",
    "            if not all(isinstance(t,str) and t.strip() for t in texts):\n",
    "                raise ValueError(\"All items must be a non-empty string .\") # Raises error if there is empty items in list .\n",
    "        else:\n",
    "            raise TypeError(\"Invalid type must be string or list of strings .\") # Raises error if the given input is invalid type .\n",
    "\n",
    "        # texts -> input -> string or List of strings .\n",
    "        # show_progress_bar -> Used to show the progress of converting texts into embeddings .\n",
    "        # normalize_embeddings -> Used for semantic search using cosine similarity .\n",
    "        # batch_size -> Parallel embedding of texts .\n",
    "        # convert_to_numpy -> Converts output to numpy array . Can also convert to tensor .\n",
    "        embeddings=self.embedding_model.encode(texts,show_progress_bar=True,normalize_embeddings=True,batch_size=batch_size,convert_to_numpy=True)\n",
    "        if embeddings.ndim==1: # Used to convert single dimension output to two dimension . Eg input -> single text .\n",
    "            embeddings=embeddings.reshape(1,-1)\n",
    "        print(f\"Generated with embedding of dimensions : {embeddings.shape[0]} x {embeddings.shape[1]}.\") # Shape of the embeddings .\n",
    "        return embeddings # Returns converted embeddings ."
   ],
   "id": "b5cd326515e592c7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:25.565913Z",
     "start_time": "2026-01-14T12:37:21.573894100Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_manager=EmbeddingManager() # Loading model by calling it .",
   "id": "e282e9a6a7fa6c8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embedding Model : all-MiniLM-L6-v2 .\n",
      "Embedding dimensions of the model is : 384 dimensions .\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:26.113631500Z",
     "start_time": "2026-01-14T12:37:25.581291700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample input for converting text into embeddings .\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "sample_texts=TextLoader(file_path=\"../data/text/file1.txt\",encoding=\"utf-8\")"
   ],
   "id": "1f739211885bd1d7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:26.174250500Z",
     "start_time": "2026-01-14T12:37:26.126662900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "texts_loader=sample_texts.load() # Loading sample text through a file .\n",
    "texts_loader[0].page_content # Using the page_content of the Document ."
   ],
   "id": "8baa30b96e87b00f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAbstract\\n\\nLarge pre-trained language models have been shown to store factual knowledge in their parameters and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems.\\n\\nPre-trained models with a differentiable access mechanism to explicit non-parametric memory have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) â€” models which combine pre-trained parametric and non-parametric memory for language generation.\\n\\nWe introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations: one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token.\\n\\nWe fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open-domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse, and factual language than a state-of-the-art parametric-only seq2seq baseline.\\n\\n1. Introduction\\n\\nPre-trained neural language models have been shown to learn a substantial amount of in-depth knowledge from data. They can do so without any access to an external memory, acting as a parameterized implicit knowledge base. While this development is exciting, such models have downsides: they cannot easily expand or revise their memory, cannot straightforwardly provide insight into their predictions, and may produce hallucinations.\\n\\nHybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Important Note: Embeddings and Metadata\n",
    "\n",
    "Embeddings are stored together with metadata such as the original text chunk and source information.\n",
    "This metadata is required to reconstruct context during retrieval."
   ],
   "id": "41d7d5c01c983c77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T12:37:26.334601700Z",
     "start_time": "2026-01-14T12:37:26.176233400Z"
    }
   },
   "cell_type": "code",
   "source": "print(embedding_manager.generate_embeddings(texts_loader[0].page_content)) # Generating embeddings .",
   "id": "9ab56d69084f8a69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "759fcd07686445abb2f3d2da21732bdb"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated with embedding of dimensions : 1 x 384.\n",
      "[[-6.82110786e-02 -5.49745858e-02 -9.45889484e-03  9.14839506e-02\n",
      "   9.89885628e-03  7.40969852e-02 -2.27620099e-02 -9.08262655e-03\n",
      "   3.26191857e-02 -2.97626834e-02  1.55247143e-02 -1.60280149e-02\n",
      "   6.23321123e-02  3.82024376e-03 -7.78601039e-03  4.69363816e-02\n",
      "   9.62595418e-02  4.51717749e-02 -8.07017609e-02 -5.44300564e-02\n",
      "   6.30562901e-02  7.01797977e-02  6.04657233e-02 -2.80444659e-02\n",
      "   9.29219648e-03 -3.76222432e-02 -3.70796956e-02 -4.02639173e-02\n",
      "   9.27506760e-02  7.15795846e-04  5.56802228e-02  3.79125066e-02\n",
      "  -9.68193635e-02  6.64731264e-02 -4.32489440e-02  9.20629352e-02\n",
      "  -9.50567052e-02  3.45189720e-02  3.56559642e-02 -7.04297870e-02\n",
      "  -1.94121583e-03 -5.44193201e-04 -3.14035825e-02  4.64817025e-02\n",
      "   7.70938247e-02  1.53455166e-02 -1.82156768e-02 -3.22249811e-03\n",
      "  -1.52310487e-02  2.01163068e-02 -1.10819988e-01  1.80859249e-02\n",
      "   2.59972103e-02  2.42232122e-02  5.33686392e-03  4.54786345e-02\n",
      "   9.83385555e-03  3.58048677e-02 -4.16282639e-02 -8.62295032e-02\n",
      "  -9.26059484e-02 -1.64832890e-01 -2.18298472e-02 -8.34843293e-02\n",
      "  -3.98602523e-02 -3.68473940e-02  3.61957215e-02  5.35170212e-02\n",
      "  -2.73333602e-02  2.65194792e-02 -4.38955054e-02  5.97699098e-02\n",
      "  -3.66448797e-03  4.70451452e-02 -3.04931942e-02  9.92070436e-02\n",
      "   2.08361093e-02 -3.49289849e-02 -1.97288450e-02 -3.32784504e-02\n",
      "   2.46348493e-02  1.54138831e-02  7.37429261e-02  7.95764290e-03\n",
      "   6.39247000e-02  7.91213065e-02  7.65071511e-02 -4.93099540e-03\n",
      "   4.38678265e-02  3.28806341e-02 -1.76837221e-02 -4.11817618e-02\n",
      "   8.80222991e-02 -3.98838781e-02  5.48907556e-02  6.89023063e-02\n",
      "   8.87271240e-02 -6.70526028e-02  6.95866533e-03  7.15947673e-02\n",
      "   1.19508326e-01  1.37974903e-01  1.96815701e-03 -1.62398592e-02\n",
      "  -1.71085335e-02 -2.86513064e-02  1.24673992e-02  7.70528316e-02\n",
      "  -3.24569754e-02 -3.75968367e-02  3.19177918e-02  8.81218836e-02\n",
      "   5.21871001e-02 -2.10979693e-02  1.33834574e-02  2.96595022e-02\n",
      "   2.13256367e-02 -3.07196844e-02  4.65765484e-02  5.47852553e-02\n",
      "  -1.88637413e-02  7.39206597e-02  2.48574205e-02  9.19764042e-02\n",
      "  -7.83816725e-02 -3.97768244e-02  1.83759723e-02 -3.15506380e-34\n",
      "   6.23435639e-02  5.14371432e-02  2.54011098e-02  2.54146811e-02\n",
      "  -4.01037000e-02  7.98420981e-03  6.03462905e-02  6.43719360e-02\n",
      "  -4.53849249e-02 -6.62599728e-02 -1.54031906e-02 -1.07223401e-02\n",
      "  -4.26268168e-02  3.75446677e-02  3.83796021e-02  1.70327965e-02\n",
      "  -9.34713036e-02  4.10226732e-02  8.80471803e-03 -5.29510016e-03\n",
      "   4.30774596e-03 -3.14296558e-02  2.11720951e-02 -4.33930270e-02\n",
      "  -1.08573204e-02 -2.24772710e-02  3.30831930e-02 -5.89917153e-02\n",
      "  -9.56816450e-02 -8.53488781e-03 -1.04243658e-01 -2.72920895e-02\n",
      "   3.18417437e-02 -1.58019364e-03 -2.86018592e-03 -4.84923534e-02\n",
      "  -2.56078914e-02 -3.81281525e-02 -2.31010970e-02 -3.13848294e-02\n",
      "   1.35352872e-02  4.39595990e-02  5.92343621e-02  1.77565068e-02\n",
      "  -8.35223049e-02 -1.59634635e-01  2.90734519e-04 -2.25138362e-03\n",
      "  -5.10205291e-02 -3.24918851e-02  6.47042021e-02  6.06379732e-02\n",
      "  -6.93776235e-02 -5.09370230e-02  6.64268881e-02 -3.52093354e-02\n",
      "   2.80434508e-02  4.56115678e-02  2.70586144e-02  9.85565782e-02\n",
      "   3.78980823e-02  3.51565778e-02  2.08078362e-02  1.06382832e-01\n",
      "   3.23595889e-02  5.05563691e-02 -4.95506711e-02  1.12645030e-01\n",
      "   8.35755020e-02 -1.73977409e-02 -1.90373044e-02 -6.62719086e-02\n",
      "   1.97342597e-02 -5.49513921e-02  4.04119231e-02 -1.23925079e-02\n",
      "   1.51751414e-02 -1.13501996e-01 -2.08219723e-03 -7.17516104e-03\n",
      "   5.60597703e-02 -5.21791764e-02  1.70931891e-02 -2.22365726e-02\n",
      "  -2.32229065e-02 -6.35425150e-02  3.90692726e-02 -9.24832821e-02\n",
      "   1.61624178e-02 -6.22735657e-02  3.25297657e-03  2.09082793e-02\n",
      "  -8.60673860e-02 -3.24886516e-02  3.20363929e-03  1.09948358e-33\n",
      "   2.72604879e-02 -4.35899124e-02 -2.11953279e-02  5.71161844e-02\n",
      "  -2.40283851e-02 -7.00561479e-02 -1.07023194e-02  1.19699677e-02\n",
      "  -8.44743624e-02 -4.02298458e-02 -7.22183138e-02 -8.15587267e-02\n",
      "   4.85178009e-02 -4.36400995e-02  4.66245264e-02 -1.80761311e-02\n",
      "  -2.16448884e-02  7.03827245e-03 -4.67636110e-03  1.16340369e-01\n",
      "  -2.56110597e-02  4.03501056e-02 -4.01399843e-02  5.66940978e-02\n",
      "  -3.53721566e-02  1.82684008e-02 -7.58707011e-03  2.50841156e-02\n",
      "  -3.58513258e-02  3.89539078e-02 -2.20161881e-02 -1.80383660e-02\n",
      "   7.15116598e-03 -9.05685127e-03 -8.05715621e-02  3.15715410e-02\n",
      "   6.89986199e-02  9.14014783e-03 -6.40699789e-02  5.52531146e-02\n",
      "   5.48348427e-02 -2.38797255e-02 -4.82561663e-02 -2.34258398e-02\n",
      "  -7.07971603e-02  3.76066044e-02 -1.38148025e-01  2.72138813e-03\n",
      "  -2.69783141e-05  2.02504639e-03  1.81571953e-02  3.84835154e-02\n",
      "  -3.88191305e-02 -3.50307510e-03 -2.76082773e-02 -1.46876410e-01\n",
      "  -9.71354023e-02 -6.45531192e-02  7.08615482e-02 -1.26571842e-02\n",
      "  -1.33588351e-02  2.03164704e-02 -3.59801352e-02 -5.13093807e-02\n",
      "   4.00938019e-02 -7.13952184e-02 -3.02060600e-02  3.24083492e-02\n",
      "  -6.12739809e-02  2.27843821e-02 -9.18212533e-03 -3.59448865e-02\n",
      "   5.15612662e-02 -5.78582250e-02  3.02827507e-02  2.96699349e-03\n",
      "   1.56668052e-02 -1.95323601e-02 -2.56908666e-02 -7.75751844e-02\n",
      "  -1.58949699e-02  6.65496513e-02  3.88967507e-02  4.05325964e-02\n",
      "   1.88765079e-02  6.48934022e-02  1.34770554e-02  6.69519827e-02\n",
      "  -3.32724638e-02  3.99413928e-02  1.74747605e-03 -2.55252179e-02\n",
      "  -3.83153632e-02  6.90458566e-02  2.74927970e-02 -3.96799003e-08\n",
      "  -4.87559736e-02  5.31378500e-02 -2.97147897e-03  1.20033063e-01\n",
      "   2.51893289e-02 -4.58054617e-02 -7.29838535e-02  6.68020621e-02\n",
      "  -2.08103694e-02 -4.22381461e-02 -1.72015689e-02  1.36585282e-02\n",
      "  -1.92808546e-02 -5.52586094e-02 -2.58698054e-02  2.16397401e-02\n",
      "   2.81381514e-02  2.78442986e-02  2.04108227e-02 -4.25997637e-02\n",
      "   4.30315211e-02  7.13648871e-02  2.74042431e-02 -1.48406783e-02\n",
      "   7.20217377e-02 -2.27889568e-02 -2.15372201e-02  5.45428284e-02\n",
      "   1.07040562e-01 -2.86424570e-02  2.48578824e-02 -3.31084095e-02\n",
      "  -2.21410524e-02 -3.36356200e-02  4.64277193e-02  7.22055063e-02\n",
      "  -3.11028529e-02 -5.47008030e-02 -2.73463819e-02 -3.25766355e-02\n",
      "   4.43131886e-02  7.11948797e-02 -6.20323196e-02  1.30649973e-02\n",
      "   1.32459141e-02 -3.13733146e-02 -6.28508106e-02 -9.78874117e-02\n",
      "   5.17248362e-02 -4.47994694e-02 -1.25101092e-03 -8.39809999e-02\n",
      "   3.94486859e-02  5.05154505e-02  6.51100501e-02  2.98875514e-02\n",
      "  -6.99282531e-03  6.13187719e-03  2.46218536e-02  1.72299612e-02\n",
      "   5.73007539e-02  5.37154749e-02 -1.98914427e-02  4.29458581e-02]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Important Note: Embeddings are NOT retrieval results\n",
    "\n",
    "After embeddings are generated:\n",
    "1. Embeddings are stored in a vector database.\n",
    "2. User queries are converted into embeddings.\n",
    "3. Similarity search is performed in the vector store.\n",
    "\n",
    "This notebook stops at step 3."
   ],
   "id": "1ae49a79b7a03472"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What comes next\n",
    "- Vector store ingestion\n",
    "- Retrieval (RAG)\n"
   ],
   "id": "2dd458b3b8048675"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Next step: Storing the embeddings into vector store.\n",
   "id": "b16c5549eff7b66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
